---
title: "R Notebook"
output:
  html_document:
    df_print: paged
    code_folding: hide
---

```{r setup, include=FALSE,echo=FALSE,warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(panelr)
library(xtsum)
library(skimr)
library(highcharter)
library(ranger)
library(tidymodels)
library(vip)

general_dt <- read_csv("general_dt.csv")
underwriting_dt <- read_csv('underwriting_dt.csv')


```

## Introduction

This report aims to analyze the performance and risk assessment of insurance companies using data analytics techniques in R. We will explore key metrics such as Gross Written Premium (GWP), Total Assets, Solvency Capital Requirement (SCR), and Gross Claims Incurred (GCI). Additionally, predictive models will be built to classify firms based on their SCR Ratio.

#### Data Cleaning and Preprocessing

```{r pressure, echo=F, error=FALSE, fig.align='center', fig.width=7, message=FALSE, warning=FALSE, paged.print=TRUE}
### CLEANING general ###
names(general_dt) <- sub(".{9}$", "", names(general_dt))
row_as_array <- as.character(unlist(general_dt[1, ]))
names(general_dt) <- paste(names(general_dt), "_", row_as_array, sep = "")


names(general_dt) <- sub(".{2}$", "", names(general_dt))

general_dt <- general_dt %>%
  rename(Firm = ...1_) %>%
  rename(SCR_2019 = `SCR _2019`) %>%
  rename(SCR_2020 = `SCR _2020`)
general_dt <- general_dt[-1,]

general_dt_panel <- long_panel(general_dt, prefix = "_", begin = 2016, end = 2020, label_location = "end")
general_dt_panel <- sapply(general_dt_panel[4:11], as.numeric)
general_dt_panel <- as.data.frame(general_dt_panel)

general_dt_panel$id <- as.factor(general_dt_panel$id)
general_dt_panel$wave <- as.factor(general_dt_panel$wave)

general_dt_panel <- panel_data(general_dt_panel, id = id, wave = wave)
knitr::kable(head(general_dt_panel))
```

The general dataset has been successfully cleaned and reshaped into a panel format, facilitating further analysis. We loaded relevant libraries for data manipulation, visualization, and modeling. Two datasets, general_dt.csv and underwriting_dt.csv, were loaded and cleaned. Data cleaning steps included removing unnecessary characters from column names, reshaping data for analysis, converting columns to numeric format, and handling missing values.

Let's start identifying potential outliers:

```{r presssure, echo=FALSE, fig.width=14, message=FALSE, warning=FALSE}

ggplot(stack(as.data.frame(general_dt_panel)), aes(x = ind, y = values)) +
  geom_boxplot()
```

Visual inspection of box plots reveals potential outliers in the data, which warrant further investigation.

We'll take care of SCR coverage Ratio later. Excluding it, the other variables in the general dataset looks fine.

```{r pressure2, echo=FALSE, fig.width=20, warning=FALSE}

ggplot(stack(as.data.frame(general_dt_panel)[-6]), aes(x = ind, y = values)) +
  geom_boxplot()
```

## CLEANING UNDERWRITING DATA

```{r 34, message=FALSE, warning=FALSE}
### CLEANING underwriting ###
names(underwriting_dt) <- sub(".{5}$", "", names(underwriting_dt))
row_as_array <- as.character(unlist(underwriting_dt[1, ]))
names(underwriting_dt) <- paste(names(underwriting_dt), "_", row_as_array, sep = "")


names(underwriting_dt) <- sub(".{2}$", "", names(underwriting_dt))

underwriting_dt <- underwriting_dt %>%
  rename(Firm = ...1_)


underwriting_dt <- underwriting_dt[-1,]

underwriting_dt_panel <- long_panel(underwriting_dt, prefix = "_", begin = 2016, end = 2020, label_location = "end")
underwriting_dt_panel <- sapply(underwriting_dt_panel[5:11], as.numeric)
underwriting_dt_panel <- as.data.frame(underwriting_dt_panel)
underwriting_dt_panel$id <- as.factor(underwriting_dt_panel$id)
underwriting_dt_panel$wave <- as.factor(underwriting_dt_panel$wave)

underwriting_dt_panel <- panel_data(underwriting_dt_panel, id = id, wave = wave)

knitr::kable(head(underwriting_dt_panel))
```

We find what most probably are imputing errors also in the underwriting dataset:

```{r preddssu, echo=FALSE, fig.width=20, message=FALSE, warning=FALSE}

ggplot(stack(as.data.frame(underwriting_dt_panel)), aes(x = ind, y = values)) +
  geom_boxplot()
```

The Firm with some of these outliers is the number 188:

```{r 4ddvd,warning=FALSE}
underwriting_dt_panel %>% 
  filter(if_any(is.numeric, ~ . > 900000))
```

```{r 4vd, fig.width=20, message=FALSE, warning=FALSE}

boxplot((underwriting_dt_panel%>% dplyr::filter(id == 188)))
knitr::kable(head(underwriting_dt_panel%>% dplyr::filter(id == 188)))
```

Another rather strange firm is the 418:

```{r sd,warning=FALSE}
underwriting_dt_panel %>% 
  filter(if_any(is.numeric, ~ . < -4000000))
```

```{r 4vfdsd, fig.width=20, message=FALSE, warning=FALSE}

boxplot((underwriting_dt_panel%>% dplyr::filter(id == 418)))
knitr::kable(head(underwriting_dt_panel%>% dplyr::filter(id == 418)))
```

## BASIC CHARTS FOR RELEVANT METRICS

Exploratory Data Analysis (EDA) Now that we have a unified dataset, let's conduct further analysis to uncover insights into the insurance companies' performance and risk assessment metrics.

Let's start with the GWP:

```{R EF, fig.width=10, message=FALSE, warning=FALSE}


full_panel <- full_join(general_dt_panel,underwriting_dt_panel)

# Let's start with some basic summay stats for the main metrics
gwp <- summary(full_panel, `GWP `, by.wave = FALSE, by.id = TRUE)
gwp <- gwp %>% dplyr::filter(!is.nan(numeric.mean))


highchart() %>%
  hc_title(text = "GWP Mean per Firm with Min and Max Value") %>%
  hc_xAxis(title = list(text = "Firms")) %>%
  hc_yAxis(title = list(text = "GWP")) %>%
  hc_add_series(gwp, type = "point", hcaes(x = id, y = numeric.mean),tooltip = list(pointFormat = "Firm ID: {point.id} ///
                                                                                    Mean: {point.y}"))%>%
  hc_add_series(gwp, type = "errorbar", hcaes(x = id, y = numeric.mean, low = numeric.p0, high = numeric.p100))

```

We can come up with the 15 biggest firms for GWP and then bind them with Total Asset to find some of the firms should receive more attention due to their size.

```{r MK,warning=FALSE}

top15_gwp <- gwp %>% arrange(desc(numeric.mean)) %>% dplyr::slice_head(n=15)
knitr::kable(head(top15_gwp))
```

```{r tota,warning=FALSE}
tota <- summary(full_panel,`Total assets `, by.wave = FALSE, by.id = TRUE)
tota <- tota %>% dplyr::filter(!is.nan(numeric.mean))


highchart() %>%
  hc_title(text = "Total Asset Mean per Firm with Min and Max Value") %>%
  hc_xAxis(title = list(text = "Firms")) %>%
  hc_yAxis(title = list(text = "Total Assets")) %>%
  hc_add_series(tota, type = "point", hcaes(x = id, y = numeric.mean),tooltip = list(pointFormat = "Firm ID: {point.id} ///
                                                                                    Mean: {point.y}"))%>%
  hc_add_series(tota, type = "errorbar", hcaes(x = id, y = numeric.mean, low = numeric.p0, high = numeric.p100))


```

We can combine the top 15 Firms for Total Assets with the top 15 GWP and being the 2 sets almost completely overlapping, we obtain 17 of the biggest Firms in the dataset.

```{r dfs, fig.width=20, message=FALSE, warning=FALSE}

top15_tota <- tota %>% arrange(desc(numeric.mean)) %>% dplyr::slice_head(n=15)
knitr::kable(head(rbind(top15_tota,top15_gwp)))
```

```{r sssd, fig.width=20}
full_panel %>% 
  dplyr::filter(`SCR coverage r` > 400000000)
```

```{r 4vddasdfav}
full_panel <- full_panel%>% dplyr::filter(!id %in% c(131,216,418,188))

```

We've removed from our data all the firms presenting probable mistakes (Firms 131,216,418,188)).\
In the next step we're going to remove other firms presenting big outliers for SCR coverage ration.

```{r ervf}

scr_r <- summary(full_panel, `SCR coverage r`, by.wave = FALSE, by.id = TRUE)
scr_r <- scr_r %>% dplyr::filter(!is.nan(numeric.mean))

scr_r_outliers <- scr_r %>% dplyr::filter(numeric.mean > 200)
knitr::kable(head(scr_r_outliers))
# removing the outliers
full_panel <- full_panel%>% dplyr::filter(!id %in% scr_r_outliers$id)
scr_r <- summary(full_panel, `SCR coverage r`, by.wave = FALSE, by.id = TRUE)
scr_r <- scr_r %>% dplyr::filter(!is.nan(numeric.mean))



highchart() %>%
  hc_title(text = "SCR_ratio Mean per Firm with Min and Max Value") %>%
  hc_xAxis(title = list(text = "Firms")) %>%
  hc_yAxis(title = list(text = "scr_ratio")) %>%
  hc_add_series(scr_r, type = "point", hcaes(x = id, y = numeric.mean),tooltip = list(pointFormat = "Firm ID: {point.id} ///
                                                                                    Mean: {point.y}"))%>%
  hc_add_series(scr_r, type = "errorbar", hcaes(x = id, y = numeric.mean, low = numeric.p0, high = numeric.p100))


```

The Solvency Capital Requirement (SCR) Coverage Ratio is a key financial metric used in the insurance industry to assess an insurance company's ability to meet its regulatory capital requirements. The SCR represents the amount of capital that an insurer is required to hold in order to ensure that it has sufficient funds to cover its insurance liabilities with a high level of confidence over a specified time horizon, typically one year. Therefore the supervisors might be interested in the worst performing ones:

```{r fesd}
knitr::kable(head(scr_r %>% arrange(numeric.mean) %>% dplyr::slice_head(n=35)))

```

#### GCI - **Gross claims incurred** 

##### a large cost to an insurer. Monitoring how these change over time for a firm is vital. 

We're now going to calculate the CAGR to assess which firms has changed the most in respect to its past years:

```{r dsg, fig.width=10, message=FALSE, warning=FALSE}
# Let's calculate the CAGR for GCI

df <- full_panel %>%
    group_by(id) %>%
    mutate(lagD = dplyr::lag(`Gross claims incurred (£m`,1), #get lad Data

         CAGR = (`Gross claims incurred (£m` / lagD)^(1/1) - 1)%>%
  select(`Gross claims incurred (£m`,CAGR) %>%
   dplyr::filter(!is.infinite(CAGR) )

df_gci_cagr <- as.data.frame(df) %>%
  arrange(desc(CAGR)) %>%
  slice_head(n=15)


full_panelx <- full_panel %>%
  dplyr::filter(id %in% df_gci_cagr$id)


#line_plot(full_panelx, `Gross claims incurred (£m`, add.mean = TRUE, alpha = 0.2)

highchart() %>%
  hc_title(text = "GCI of 15 Firms with highest CAGR") %>%
  hc_xAxis(title = list(text = "Firms")) %>%
  hc_yAxis(title = list(text = "GCI")) %>%
  hc_add_series(full_panelx, type = "line", hcaes(name = id, y = `Gross claims incurred (£m`, x = wave), tooltip = list(pointFormat = "Firm ID: {point.id} ///
                                                                                    CGI: {point.y}"))

```

#### TASK 2

For this second task, we're going to create a new feature from SCR Coverage Ratio by defining in a binary fashion if a firm has reached its coverage goal or not.

The new variable will be 1 if the ratio is 100% or above, 0 otherwise.

We're going to try two standard algorithms such as Random Forest and Support Vector Machine to try to correctly classify SCR Ratio.

We're going to split the data into training, testing, and validation sets using a 70-10-20 split ratio. Then, we're going to prepare the "recipe" for the models, defining the parameter that need to be tuned and setting few reprocessing steps.

We can see from the above ROC AUC chart that the two models have no big difference in performance. Indeed none of them is actually good, leaving us with future challenges:

We could further investgate

-   **Correlation Analysis:** correlation coefficients between various financial metrics to identify potential relationships. High correlations between features might suggest redundancy, and feature selection techniques could be employed for model improvement.

-   **Alternative Modeling Techniques:** Exploring the potential benefits of using other classification models like Logistic Regression, Gradient Boosting Machines, or Neural Networks depending on the data characteristics and problem complexity.

-   **Feature Engineering Exploration:** Considering alternative feature engineering techniques like feature scaling, binning categorical variables, or creating interaction terms between features to potentially improve model performance.

```{r rrt}

# Fix the random numbers by setting the seed
# This enables the analysis to be reproducible when random numbers are used
set.seed(222)
# Put 3/4 of the data into the training set
#full_panel$id <-  as.numeric(as.data.frame(full_panel)$id)
full_panel <- as.data.frame(full_panel)
full_panel$`Gross BEL (inc. TPs as whole, pre-TMTP) (£m` <- NULL
full_panel <- full_panel[complete.cases(full_panel),]
full_panel$id <- NULL
full_panel$wave <- NULL

# Mutate the variable 'x' based on your condition
full_panel <- full_panel %>%
  mutate(.keep = 'unused', SCR_ratio = ifelse(`SCR coverage r` < 1, 0, ifelse(`SCR coverage r` >= 1, 1, `SCR coverage r`)))

full_panel$SCR_ratio <- as.factor(full_panel$SCR_ratio)
data_split <- initial_validation_split(full_panel, prop = c(.7,.1))

# Create data frames for the two sets:
train_data <- training(data_split)
test_data  <- testing(data_split)
val_set <- validation(data_split)

cores <- parallel::detectCores()


rf_mod <-
  rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
  set_engine("ranger", num.threads = cores) %>%
  set_mode("classification")

svm_mod <-
  svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
  set_mode("classification") %>%
  set_engine("kernlab")

rf_recipe <-
  recipe(SCR_ratio ~ ., data = train_data) %>%
# remove any zero variance predictors
step_zv(all_predictors()) %>%
  # remove any linear combinations
  step_lincomb(all_numeric())


svm_recipe <-
  recipe(SCR_ratio ~ ., data = train_data)  %>%
  # remove any zero variance predictors
  step_zv(all_predictors()) %>%
  # remove any linear combinations
  step_lincomb(all_numeric())

rf_workflow <-
  workflow() %>%
  add_model(rf_mod) %>%
  add_recipe(rf_recipe)


svm_workflow <-
  workflow() %>%
  add_model(svm_mod) %>%
  add_recipe(svm_recipe)


set.seed(42)
rf_res <-
  rf_workflow %>%
  tune_grid(
    resamples = vfold_cv(val_set),
            grid = 25,
            control = control_grid(save_pred = T,verbose = F),
            metrics = metric_set(roc_auc))

svm_res <-
  rf_workflow %>%
  tune_grid(
    resamples = vfold_cv(val_set),
    grid = 25,
    control = control_grid(save_pred = T,verbose = F),
    metrics = metric_set(roc_auc))



```

```{r dfsllko}

rf_best <-
  rf_res %>%
  select_best(metric = "roc_auc")

rf_auc <-
  rf_res %>%
  collect_predictions(parameters = rf_best) %>%
  roc_curve(SCR_ratio , .pred_0) %>%
  mutate(model = "Random Forest")


svm_best <-
  svm_res %>%
  select_best(metric = "roc_auc")

svm_auc <-
  svm_res %>%
  collect_predictions(parameters = svm_best) %>%
  roc_curve(SCR_ratio , .pred_0) %>%
  mutate(model = "SVM")

bind_rows(rf_auc, svm_auc) %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) +
  geom_path(lwd = 1.5, alpha = 0.8) +
  geom_abline(lty = 3) +
  coord_equal() +
  scale_color_viridis_d(option = "plasma", end = .6)

```

```{r final}

# the last model
last_rf_mod <-
  rand_forest(mtry = 5, min_n = 38, trees = 1000) %>%
  set_engine("ranger", num.threads = cores, importance = "impurity") %>%
  set_mode("classification")

# the last workflow
last_rf_workflow <-
  rf_workflow %>%
  update_model(last_rf_mod)

# the last fit
set.seed(345)
last_rf_fit <-
  last_rf_workflow %>%
  last_fit(data_split)


last_rf_fit %>%
  extract_fit_parsnip() %>%
  vip::vip(num_features = 20)

```

We can finally see a graph of feature importance for the Random Forest selected for deployment.

### Conclusions

This report provides a comprehensive analysis of data for multiple firms. We identified key financial metrics, explored potential relationships between them, and built models to predict a firm's potential financial health. The insights gained from the feature importance analysis provide valuable information about the factors that most influence a firm's financial standing. Further exploration and model development using the techniques discussed can lead to a more robust and generalizable approach to predicting firm financial health.

## TASK 3

Microsoft Azure Data Lake Storage (ADLS) serves as a central hub for storing raw and processed versions of our financial data. ADLS is well suited for this task because of its scalability, cost-effectiveness for large data sets, and seamless integration with other Azure services. Security plays a key role, so access control and encryption policies will be defined within ADLS to safeguard sensitive financial information.

Bringing data in-house:

Automatic retrieval of data from various sources (databases, APIs) becomes a reality with Azure Data Factory (ADF). This serverless service acts as a master, orchestrating the movement of data between the source and the final destination-ADLS. ADF can be scheduled to trigger data retrieval every day, ensuring a constant flow of fresh financial information. When the data arrives, ADF's built-in error handling and validation steps ensure its quality and integrity before it reaches ADLS.

Making the data sing:

Once the data is securely stored, Azure Databricks comes into the picture. This powerful service, based on Apache Spark, provides the ideal environment for large-scale data processing tasks. Using Databricks notebooks, we can implement the data cleansing, transformation, and engineering steps described earlier in the report. To optimize the useful

**The Power of Batch Processing:**

Daily batch processing becomes a reality through ADF's scheduling capabilities. These capabilities allow us to trigger data ingestion and processing tasks on a daily basis. Defining dependencies between pipeline activities ensures proper execution order and a smooth flow of data through the pipeline. Monitoring alerts within Azure services keep us informed of the pipeline's execution status, allowing for swift identification and resolution of any potential errors or delays.

**Conclusion:**

By leveraging Microsoft Azure's cloud services, we can create a robust, scalable, and secure end-to-end data processing and analytics pipeline for the financial analysis report. This approach allows for automated daily batch processing, enabling continuous insights into the financial health of our firms. Remember, the specifics of the pipeline can be customized based on the unique data sources, processing requirements, and security needs of your organization.
